name: "SE-ResNet-50"

layer {
	name: "data"
	type: "Python"
	top: "data"
	top: "gt_regression_attribute"
	python_param {
		module: "python_data_layer"
		layer: "JointDataLayer"
		param_str: "{'split_name_0': 'train', 'split_name_1': 'val'}"
	}
	include {
		phase: TRAIN
	}
}

layer {
	name: "data"
	type: "Python"
	top: "data"
	top: "gt_regression_attribute"
	python_param {
		module: "python_data_layer"
		layer: "DataLayer"
		param_str: "{'split_name': 'val'}"
	}
	include {
		phase: TEST
	}
}

#----------------------------------------------------------------

layer {
  name: "conv1/7x7_s2"
  type: "Convolution"
  bottom: "data"
  top: "conv1/7x7_s2"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "conv1/7x7_s2/bn"
  type: "BatchNorm"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/7x7_s2/bn/scale"
  type: "Scale"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/relu_7x7_s2"
  type: "ReLU"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2"
}
layer {
  name: "pool1/3x3_s2"
  type: "Pooling"
  bottom: "conv1/7x7_s2"
  top: "pool1/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_1_1x1_reduce"
  type: "Convolution"
  bottom: "pool1/3x3_s2"
  top: "conv2_1_1x1_reduce"
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_1x1_reduce"
}
layer {
  name: "conv2_1_3x3"
  type: "Convolution"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_3x3"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv2_1_3x3/bn"
  type: "BatchNorm"
  bottom: "conv2_1_3x3"
  top: "conv2_1_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_3x3/bn/scale"
  type: "Scale"
  bottom: "conv2_1_3x3"
  top: "conv2_1_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_3x3/relu"
  type: "ReLU"
  bottom: "conv2_1_3x3"
  top: "conv2_1_3x3"
}
layer {
  name: "conv2_1_1x1_increase"
  type: "Convolution"
  bottom: "conv2_1_3x3"
  top: "conv2_1_1x1_increase"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv2_1_1x1_increase"
  top: "conv2_1_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv2_1_1x1_increase"
  top: "conv2_1_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_global_pool"
  type: "Pooling"
  bottom: "conv2_1_1x1_increase"
  top: "conv2_1_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv2_1_1x1_down"
  type: "Convolution"
  bottom: "conv2_1_global_pool"
  top: "conv2_1_1x1_down"
  convolution_param {
    num_output: 16
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_1x1_down/relu"
  type: "ReLU"
  bottom: "conv2_1_1x1_down"
  top: "conv2_1_1x1_down"
}
layer {
  name: "conv2_1_1x1_up"
  type: "Convolution"
  bottom: "conv2_1_1x1_down"
  top: "conv2_1_1x1_up"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_prob"
  type: "Sigmoid"
  bottom: "conv2_1_1x1_up"
  top: "conv2_1_1x1_up"
}
layer {
  name: "conv2_1_1x1_proj"
  type: "Convolution"
  bottom: "pool1/3x3_s2"
  top: "conv2_1_1x1_proj"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_1x1_proj/bn"
  type: "BatchNorm"
  bottom: "conv2_1_1x1_proj"
  top: "conv2_1_1x1_proj"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_1x1_proj/bn/scale"
  type: "Scale"
  bottom: "conv2_1_1x1_proj"
  top: "conv2_1_1x1_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Axpy"
  bottom: "conv2_1_1x1_up"
  bottom: "conv2_1_1x1_increase"
  bottom: "conv2_1_1x1_proj"
  top: "conv2_1"
}
layer {
  name: "conv2_1/relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2_1x1_reduce"
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_2_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_1x1_reduce"
}
layer {
  name: "conv2_2_3x3"
  type: "Convolution"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_3x3"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv2_2_3x3/bn"
  type: "BatchNorm"
  bottom: "conv2_2_3x3"
  top: "conv2_2_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_3x3/bn/scale"
  type: "Scale"
  bottom: "conv2_2_3x3"
  top: "conv2_2_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_3x3/relu"
  type: "ReLU"
  bottom: "conv2_2_3x3"
  top: "conv2_2_3x3"
}
layer {
  name: "conv2_2_1x1_increase"
  type: "Convolution"
  bottom: "conv2_2_3x3"
  top: "conv2_2_1x1_increase"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_2_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv2_2_1x1_increase"
  top: "conv2_2_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv2_2_1x1_increase"
  top: "conv2_2_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_global_pool"
  type: "Pooling"
  bottom: "conv2_2_1x1_increase"
  top: "conv2_2_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv2_2_1x1_down"
  type: "Convolution"
  bottom: "conv2_2_global_pool"
  top: "conv2_2_1x1_down"
  convolution_param {
    num_output: 16
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_2_1x1_down/relu"
  type: "ReLU"
  bottom: "conv2_2_1x1_down"
  top: "conv2_2_1x1_down"
}
layer {
  name: "conv2_2_1x1_up"
  type: "Convolution"
  bottom: "conv2_2_1x1_down"
  top: "conv2_2_1x1_up"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_2_prob"
  type: "Sigmoid"
  bottom: "conv2_2_1x1_up"
  top: "conv2_2_1x1_up"
}
layer {
  name: "conv2_2"
  type: "Axpy"
  bottom: "conv2_2_1x1_up"
  bottom: "conv2_2_1x1_increase"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2/relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3_1x1_reduce"
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_3_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_1x1_reduce"
}
layer {
  name: "conv2_3_3x3"
  type: "Convolution"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_3x3"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv2_3_3x3/bn"
  type: "BatchNorm"
  bottom: "conv2_3_3x3"
  top: "conv2_3_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_3x3/bn/scale"
  type: "Scale"
  bottom: "conv2_3_3x3"
  top: "conv2_3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_3x3/relu"
  type: "ReLU"
  bottom: "conv2_3_3x3"
  top: "conv2_3_3x3"
}
layer {
  name: "conv2_3_1x1_increase"
  type: "Convolution"
  bottom: "conv2_3_3x3"
  top: "conv2_3_1x1_increase"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_3_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv2_3_1x1_increase"
  top: "conv2_3_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv2_3_1x1_increase"
  top: "conv2_3_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_global_pool"
  type: "Pooling"
  bottom: "conv2_3_1x1_increase"
  top: "conv2_3_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv2_3_1x1_down"
  type: "Convolution"
  bottom: "conv2_3_global_pool"
  top: "conv2_3_1x1_down"
  convolution_param {
    num_output: 16
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_3_1x1_down/relu"
  type: "ReLU"
  bottom: "conv2_3_1x1_down"
  top: "conv2_3_1x1_down"
}
layer {
  name: "conv2_3_1x1_up"
  type: "Convolution"
  bottom: "conv2_3_1x1_down"
  top: "conv2_3_1x1_up"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_3_prob"
  type: "Sigmoid"
  bottom: "conv2_3_1x1_up"
  top: "conv2_3_1x1_up"
}
layer {
  name: "conv2_3"
  type: "Axpy"
  bottom: "conv2_3_1x1_up"
  bottom: "conv2_3_1x1_increase"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3/relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv3_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1_1x1_reduce"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv3_1_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_1x1_reduce"
}
layer {
  name: "conv3_1_3x3"
  type: "Convolution"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_3x3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv3_1_3x3/bn"
  type: "BatchNorm"
  bottom: "conv3_1_3x3"
  top: "conv3_1_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_3x3/bn/scale"
  type: "Scale"
  bottom: "conv3_1_3x3"
  top: "conv3_1_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_3x3/relu"
  type: "ReLU"
  bottom: "conv3_1_3x3"
  top: "conv3_1_3x3"
}
layer {
  name: "conv3_1_1x1_increase"
  type: "Convolution"
  bottom: "conv3_1_3x3"
  top: "conv3_1_1x1_increase"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_1_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv3_1_1x1_increase"
  top: "conv3_1_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv3_1_1x1_increase"
  top: "conv3_1_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_global_pool"
  type: "Pooling"
  bottom: "conv3_1_1x1_increase"
  top: "conv3_1_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv3_1_1x1_down"
  type: "Convolution"
  bottom: "conv3_1_global_pool"
  top: "conv3_1_1x1_down"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_1_1x1_down/relu"
  type: "ReLU"
  bottom: "conv3_1_1x1_down"
  top: "conv3_1_1x1_down"
}
layer {
  name: "conv3_1_1x1_up"
  type: "Convolution"
  bottom: "conv3_1_1x1_down"
  top: "conv3_1_1x1_up"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_1_prob"
  type: "Sigmoid"
  bottom: "conv3_1_1x1_up"
  top: "conv3_1_1x1_up"
}
layer {
  name: "conv3_1_1x1_proj"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1_1x1_proj"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv3_1_1x1_proj/bn"
  type: "BatchNorm"
  bottom: "conv3_1_1x1_proj"
  top: "conv3_1_1x1_proj"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_1x1_proj/bn/scale"
  type: "Scale"
  bottom: "conv3_1_1x1_proj"
  top: "conv3_1_1x1_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Axpy"
  bottom: "conv3_1_1x1_up"
  bottom: "conv3_1_1x1_increase"
  bottom: "conv3_1_1x1_proj"
  top: "conv3_1"
}
layer {
  name: "conv3_1/relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2_1x1_reduce"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_2_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_1x1_reduce"
}
layer {
  name: "conv3_2_3x3"
  type: "Convolution"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_3x3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv3_2_3x3/bn"
  type: "BatchNorm"
  bottom: "conv3_2_3x3"
  top: "conv3_2_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_3x3/bn/scale"
  type: "Scale"
  bottom: "conv3_2_3x3"
  top: "conv3_2_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_3x3/relu"
  type: "ReLU"
  bottom: "conv3_2_3x3"
  top: "conv3_2_3x3"
}
layer {
  name: "conv3_2_1x1_increase"
  type: "Convolution"
  bottom: "conv3_2_3x3"
  top: "conv3_2_1x1_increase"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_2_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv3_2_1x1_increase"
  top: "conv3_2_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv3_2_1x1_increase"
  top: "conv3_2_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_global_pool"
  type: "Pooling"
  bottom: "conv3_2_1x1_increase"
  top: "conv3_2_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv3_2_1x1_down"
  type: "Convolution"
  bottom: "conv3_2_global_pool"
  top: "conv3_2_1x1_down"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_2_1x1_down/relu"
  type: "ReLU"
  bottom: "conv3_2_1x1_down"
  top: "conv3_2_1x1_down"
}
layer {
  name: "conv3_2_1x1_up"
  type: "Convolution"
  bottom: "conv3_2_1x1_down"
  top: "conv3_2_1x1_up"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_2_prob"
  type: "Sigmoid"
  bottom: "conv3_2_1x1_up"
  top: "conv3_2_1x1_up"
}
layer {
  name: "conv3_2"
  type: "Axpy"
  bottom: "conv3_2_1x1_up"
  bottom: "conv3_2_1x1_increase"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2/relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3_1x1_reduce"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_3_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_1x1_reduce"
}
layer {
  name: "conv3_3_3x3"
  type: "Convolution"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_3x3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv3_3_3x3/bn"
  type: "BatchNorm"
  bottom: "conv3_3_3x3"
  top: "conv3_3_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_3x3/bn/scale"
  type: "Scale"
  bottom: "conv3_3_3x3"
  top: "conv3_3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_3x3/relu"
  type: "ReLU"
  bottom: "conv3_3_3x3"
  top: "conv3_3_3x3"
}
layer {
  name: "conv3_3_1x1_increase"
  type: "Convolution"
  bottom: "conv3_3_3x3"
  top: "conv3_3_1x1_increase"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_3_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv3_3_1x1_increase"
  top: "conv3_3_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv3_3_1x1_increase"
  top: "conv3_3_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_global_pool"
  type: "Pooling"
  bottom: "conv3_3_1x1_increase"
  top: "conv3_3_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv3_3_1x1_down"
  type: "Convolution"
  bottom: "conv3_3_global_pool"
  top: "conv3_3_1x1_down"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_3_1x1_down/relu"
  type: "ReLU"
  bottom: "conv3_3_1x1_down"
  top: "conv3_3_1x1_down"
}
layer {
  name: "conv3_3_1x1_up"
  type: "Convolution"
  bottom: "conv3_3_1x1_down"
  top: "conv3_3_1x1_up"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_3_prob"
  type: "Sigmoid"
  bottom: "conv3_3_1x1_up"
  top: "conv3_3_1x1_up"
}
layer {
  name: "conv3_3"
  type: "Axpy"
  bottom: "conv3_3_1x1_up"
  bottom: "conv3_3_1x1_increase"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3/relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_4_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_4_1x1_reduce"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_4_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_1x1_reduce"
}
layer {
  name: "conv3_4_3x3"
  type: "Convolution"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_3x3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv3_4_3x3/bn"
  type: "BatchNorm"
  bottom: "conv3_4_3x3"
  top: "conv3_4_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_3x3/bn/scale"
  type: "Scale"
  bottom: "conv3_4_3x3"
  top: "conv3_4_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_3x3/relu"
  type: "ReLU"
  bottom: "conv3_4_3x3"
  top: "conv3_4_3x3"
}
layer {
  name: "conv3_4_1x1_increase"
  type: "Convolution"
  bottom: "conv3_4_3x3"
  top: "conv3_4_1x1_increase"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_4_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv3_4_1x1_increase"
  top: "conv3_4_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv3_4_1x1_increase"
  top: "conv3_4_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_global_pool"
  type: "Pooling"
  bottom: "conv3_4_1x1_increase"
  top: "conv3_4_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv3_4_1x1_down"
  type: "Convolution"
  bottom: "conv3_4_global_pool"
  top: "conv3_4_1x1_down"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_4_1x1_down/relu"
  type: "ReLU"
  bottom: "conv3_4_1x1_down"
  top: "conv3_4_1x1_down"
}
layer {
  name: "conv3_4_1x1_up"
  type: "Convolution"
  bottom: "conv3_4_1x1_down"
  top: "conv3_4_1x1_up"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_4_prob"
  type: "Sigmoid"
  bottom: "conv3_4_1x1_up"
  top: "conv3_4_1x1_up"
}
layer {
  name: "conv3_4"
  type: "Axpy"
  bottom: "conv3_4_1x1_up"
  bottom: "conv3_4_1x1_increase"
  bottom: "conv3_3"
  top: "conv3_4"
}
layer {
  name: "conv3_4/relu"
  type: "ReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "conv4_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv4_1_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv4_1_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_1x1_reduce"
}
layer {
  name: "conv4_1_3x3"
  type: "Convolution"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_1_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_1_3x3"
  top: "conv4_1_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_1_3x3"
  top: "conv4_1_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_3x3/relu"
  type: "ReLU"
  bottom: "conv4_1_3x3"
  top: "conv4_1_3x3"
}
layer {
  name: "conv4_1_1x1_increase"
  type: "Convolution"
  bottom: "conv4_1_3x3"
  top: "conv4_1_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_1_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_1_1x1_increase"
  top: "conv4_1_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_1_1x1_increase"
  top: "conv4_1_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_global_pool"
  type: "Pooling"
  bottom: "conv4_1_1x1_increase"
  top: "conv4_1_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_1_1x1_down"
  type: "Convolution"
  bottom: "conv4_1_global_pool"
  top: "conv4_1_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_1_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_1_1x1_down"
  top: "conv4_1_1x1_down"
}
layer {
  name: "conv4_1_1x1_up"
  type: "Convolution"
  bottom: "conv4_1_1x1_down"
  top: "conv4_1_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_1_prob"
  type: "Sigmoid"
  bottom: "conv4_1_1x1_up"
  top: "conv4_1_1x1_up"
}
layer {
  name: "conv4_1_1x1_proj"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv4_1_1x1_proj"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv4_1_1x1_proj/bn"
  type: "BatchNorm"
  bottom: "conv4_1_1x1_proj"
  top: "conv4_1_1x1_proj"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_1x1_proj/bn/scale"
  type: "Scale"
  bottom: "conv4_1_1x1_proj"
  top: "conv4_1_1x1_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Axpy"
  bottom: "conv4_1_1x1_up"
  bottom: "conv4_1_1x1_increase"
  bottom: "conv4_1_1x1_proj"
  top: "conv4_1"
}
layer {
  name: "conv4_1/relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_2_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_1x1_reduce"
}
layer {
  name: "conv4_2_3x3"
  type: "Convolution"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_2_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_2_3x3"
  top: "conv4_2_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_2_3x3"
  top: "conv4_2_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_3x3/relu"
  type: "ReLU"
  bottom: "conv4_2_3x3"
  top: "conv4_2_3x3"
}
layer {
  name: "conv4_2_1x1_increase"
  type: "Convolution"
  bottom: "conv4_2_3x3"
  top: "conv4_2_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_2_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_2_1x1_increase"
  top: "conv4_2_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_2_1x1_increase"
  top: "conv4_2_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_global_pool"
  type: "Pooling"
  bottom: "conv4_2_1x1_increase"
  top: "conv4_2_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_2_1x1_down"
  type: "Convolution"
  bottom: "conv4_2_global_pool"
  top: "conv4_2_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_2_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_2_1x1_down"
  top: "conv4_2_1x1_down"
}
layer {
  name: "conv4_2_1x1_up"
  type: "Convolution"
  bottom: "conv4_2_1x1_down"
  top: "conv4_2_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_2_prob"
  type: "Sigmoid"
  bottom: "conv4_2_1x1_up"
  top: "conv4_2_1x1_up"
}
layer {
  name: "conv4_2"
  type: "Axpy"
  bottom: "conv4_2_1x1_up"
  bottom: "conv4_2_1x1_increase"
  bottom: "conv4_1"
  top: "conv4_2"
}
layer {
  name: "conv4_2/relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_3_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_1x1_reduce"
}
layer {
  name: "conv4_3_3x3"
  type: "Convolution"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_3_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_3_3x3"
  top: "conv4_3_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_3_3x3"
  top: "conv4_3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_3x3/relu"
  type: "ReLU"
  bottom: "conv4_3_3x3"
  top: "conv4_3_3x3"
}
layer {
  name: "conv4_3_1x1_increase"
  type: "Convolution"
  bottom: "conv4_3_3x3"
  top: "conv4_3_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_3_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_3_1x1_increase"
  top: "conv4_3_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_3_1x1_increase"
  top: "conv4_3_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_global_pool"
  type: "Pooling"
  bottom: "conv4_3_1x1_increase"
  top: "conv4_3_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_3_1x1_down"
  type: "Convolution"
  bottom: "conv4_3_global_pool"
  top: "conv4_3_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_3_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_3_1x1_down"
  top: "conv4_3_1x1_down"
}
layer {
  name: "conv4_3_1x1_up"
  type: "Convolution"
  bottom: "conv4_3_1x1_down"
  top: "conv4_3_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_3_prob"
  type: "Sigmoid"
  bottom: "conv4_3_1x1_up"
  top: "conv4_3_1x1_up"
}
layer {
  name: "conv4_3"
  type: "Axpy"
  bottom: "conv4_3_1x1_up"
  bottom: "conv4_3_1x1_increase"
  bottom: "conv4_2"
  top: "conv4_3"
}
layer {
  name: "conv4_3/relu"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_4_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv4_4_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_4_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_1x1_reduce"
}
layer {
  name: "conv4_4_3x3"
  type: "Convolution"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_4_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_4_3x3"
  top: "conv4_4_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_4_3x3"
  top: "conv4_4_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4_3x3/relu"
  type: "ReLU"
  bottom: "conv4_4_3x3"
  top: "conv4_4_3x3"
}
layer {
  name: "conv4_4_1x1_increase"
  type: "Convolution"
  bottom: "conv4_4_3x3"
  top: "conv4_4_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_4_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_4_1x1_increase"
  top: "conv4_4_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_4_1x1_increase"
  top: "conv4_4_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4_global_pool"
  type: "Pooling"
  bottom: "conv4_4_1x1_increase"
  top: "conv4_4_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_4_1x1_down"
  type: "Convolution"
  bottom: "conv4_4_global_pool"
  top: "conv4_4_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_4_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_4_1x1_down"
  top: "conv4_4_1x1_down"
}
layer {
  name: "conv4_4_1x1_up"
  type: "Convolution"
  bottom: "conv4_4_1x1_down"
  top: "conv4_4_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_4_prob"
  type: "Sigmoid"
  bottom: "conv4_4_1x1_up"
  top: "conv4_4_1x1_up"
}
layer {
  name: "conv4_4"
  type: "Axpy"
  bottom: "conv4_4_1x1_up"
  bottom: "conv4_4_1x1_increase"
  bottom: "conv4_3"
  top: "conv4_4"
}
layer {
  name: "conv4_4/relu"
  type: "ReLU"
  bottom: "conv4_4"
  top: "conv4_4"
}
layer {
  name: "conv4_5_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_4"
  top: "conv4_5_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_5_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_5_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_5_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_1x1_reduce"
}
layer {
  name: "conv4_5_3x3"
  type: "Convolution"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_5_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_5_3x3"
  top: "conv4_5_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_5_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_5_3x3"
  top: "conv4_5_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_5_3x3/relu"
  type: "ReLU"
  bottom: "conv4_5_3x3"
  top: "conv4_5_3x3"
}
layer {
  name: "conv4_5_1x1_increase"
  type: "Convolution"
  bottom: "conv4_5_3x3"
  top: "conv4_5_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_5_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_5_1x1_increase"
  top: "conv4_5_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_5_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_5_1x1_increase"
  top: "conv4_5_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_5_global_pool"
  type: "Pooling"
  bottom: "conv4_5_1x1_increase"
  top: "conv4_5_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_5_1x1_down"
  type: "Convolution"
  bottom: "conv4_5_global_pool"
  top: "conv4_5_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_5_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_5_1x1_down"
  top: "conv4_5_1x1_down"
}
layer {
  name: "conv4_5_1x1_up"
  type: "Convolution"
  bottom: "conv4_5_1x1_down"
  top: "conv4_5_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_5_prob"
  type: "Sigmoid"
  bottom: "conv4_5_1x1_up"
  top: "conv4_5_1x1_up"
}
layer {
  name: "conv4_5"
  type: "Axpy"
  bottom: "conv4_5_1x1_up"
  bottom: "conv4_5_1x1_increase"
  bottom: "conv4_4"
  top: "conv4_5"
}
layer {
  name: "conv4_5/relu"
  type: "ReLU"
  bottom: "conv4_5"
  top: "conv4_5"
}
layer {
  name: "conv4_6_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_5"
  top: "conv4_6_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_6_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_6_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_6_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_1x1_reduce"
}
layer {
  name: "conv4_6_3x3"
  type: "Convolution"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_6_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_6_3x3"
  top: "conv4_6_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_6_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_6_3x3"
  top: "conv4_6_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_6_3x3/relu"
  type: "ReLU"
  bottom: "conv4_6_3x3"
  top: "conv4_6_3x3"
}
layer {
  name: "conv4_6_1x1_increase"
  type: "Convolution"
  bottom: "conv4_6_3x3"
  top: "conv4_6_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_6_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_6_1x1_increase"
  top: "conv4_6_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_6_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_6_1x1_increase"
  top: "conv4_6_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_6_global_pool"
  type: "Pooling"
  bottom: "conv4_6_1x1_increase"
  top: "conv4_6_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_6_1x1_down"
  type: "Convolution"
  bottom: "conv4_6_global_pool"
  top: "conv4_6_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_6_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_6_1x1_down"
  top: "conv4_6_1x1_down"
}
layer {
  name: "conv4_6_1x1_up"
  type: "Convolution"
  bottom: "conv4_6_1x1_down"
  top: "conv4_6_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_6_prob"
  type: "Sigmoid"
  bottom: "conv4_6_1x1_up"
  top: "conv4_6_1x1_up"
}
layer {
  name: "conv4_6"
  type: "Axpy"
  bottom: "conv4_6_1x1_up"
  bottom: "conv4_6_1x1_increase"
  bottom: "conv4_5"
  top: "conv4_6"
}
layer {
  name: "conv4_6/relu"
  type: "ReLU"
  bottom: "conv4_6"
  top: "conv4_6"
}
layer {
  name: "conv5_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_6"
  top: "conv5_1_1x1_reduce"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv5_1_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_1x1_reduce"
}
layer {
  name: "conv5_1_3x3"
  type: "Convolution"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_3x3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv5_1_3x3/bn"
  type: "BatchNorm"
  bottom: "conv5_1_3x3"
  top: "conv5_1_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1_3x3/bn/scale"
  type: "Scale"
  bottom: "conv5_1_3x3"
  top: "conv5_1_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_3x3/relu"
  type: "ReLU"
  bottom: "conv5_1_3x3"
  top: "conv5_1_3x3"
}
layer {
  name: "conv5_1_1x1_increase"
  type: "Convolution"
  bottom: "conv5_1_3x3"
  top: "conv5_1_1x1_increase"
  convolution_param {
    num_output: 2048
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_1_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv5_1_1x1_increase"
  top: "conv5_1_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv5_1_1x1_increase"
  top: "conv5_1_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_global_pool"
  type: "Pooling"
  bottom: "conv5_1_1x1_increase"
  top: "conv5_1_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv5_1_1x1_down"
  type: "Convolution"
  bottom: "conv5_1_global_pool"
  top: "conv5_1_1x1_down"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_1_1x1_down/relu"
  type: "ReLU"
  bottom: "conv5_1_1x1_down"
  top: "conv5_1_1x1_down"
}
layer {
  name: "conv5_1_1x1_up"
  type: "Convolution"
  bottom: "conv5_1_1x1_down"
  top: "conv5_1_1x1_up"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_1_prob"
  type: "Sigmoid"
  bottom: "conv5_1_1x1_up"
  top: "conv5_1_1x1_up"
}
layer {
  name: "conv5_1_1x1_proj"
  type: "Convolution"
  bottom: "conv4_6"
  top: "conv5_1_1x1_proj"
  convolution_param {
    num_output: 2048
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv5_1_1x1_proj/bn"
  type: "BatchNorm"
  bottom: "conv5_1_1x1_proj"
  top: "conv5_1_1x1_proj"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1_1x1_proj/bn/scale"
  type: "Scale"
  bottom: "conv5_1_1x1_proj"
  top: "conv5_1_1x1_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1"
  type: "Axpy"
  bottom: "conv5_1_1x1_up"
  bottom: "conv5_1_1x1_increase"
  bottom: "conv5_1_1x1_proj"
  top: "conv5_1"
}
layer {
  name: "conv5_1/relu"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2_1x1_reduce"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_2_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_1x1_reduce"
}
layer {
  name: "conv5_2_3x3"
  type: "Convolution"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_3x3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv5_2_3x3/bn"
  type: "BatchNorm"
  bottom: "conv5_2_3x3"
  top: "conv5_2_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2_3x3/bn/scale"
  type: "Scale"
  bottom: "conv5_2_3x3"
  top: "conv5_2_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2_3x3/relu"
  type: "ReLU"
  bottom: "conv5_2_3x3"
  top: "conv5_2_3x3"
}
layer {
  name: "conv5_2_1x1_increase"
  type: "Convolution"
  bottom: "conv5_2_3x3"
  top: "conv5_2_1x1_increase"
  convolution_param {
    num_output: 2048
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_2_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv5_2_1x1_increase"
  top: "conv5_2_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv5_2_1x1_increase"
  top: "conv5_2_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2_global_pool"
  type: "Pooling"
  bottom: "conv5_2_1x1_increase"
  top: "conv5_2_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv5_2_1x1_down"
  type: "Convolution"
  bottom: "conv5_2_global_pool"
  top: "conv5_2_1x1_down"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_2_1x1_down/relu"
  type: "ReLU"
  bottom: "conv5_2_1x1_down"
  top: "conv5_2_1x1_down"
}
layer {
  name: "conv5_2_1x1_up"
  type: "Convolution"
  bottom: "conv5_2_1x1_down"
  top: "conv5_2_1x1_up"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_2_prob"
  type: "Sigmoid"
  bottom: "conv5_2_1x1_up"
  top: "conv5_2_1x1_up"
}
layer {
  name: "conv5_2"
  type: "Axpy"
  bottom: "conv5_2_1x1_up"
  bottom: "conv5_2_1x1_increase"
  bottom: "conv5_1"
  top: "conv5_2"
}
layer {
  name: "conv5_2/relu"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3_1x1_reduce"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_3_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_1x1_reduce"
}
layer {
  name: "conv5_3_3x3"
  type: "Convolution"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_3x3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv5_3_3x3/bn"
  type: "BatchNorm"
  bottom: "conv5_3_3x3"
  top: "conv5_3_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3_3x3/bn/scale"
  type: "Scale"
  bottom: "conv5_3_3x3"
  top: "conv5_3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3_3x3/relu"
  type: "ReLU"
  bottom: "conv5_3_3x3"
  top: "conv5_3_3x3"
}
layer {
  name: "conv5_3_1x1_increase"
  type: "Convolution"
  bottom: "conv5_3_3x3"
  top: "conv5_3_1x1_increase"
  convolution_param {
    num_output: 2048
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_3_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv5_3_1x1_increase"
  top: "conv5_3_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv5_3_1x1_increase"
  top: "conv5_3_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3_global_pool"
  type: "Pooling"
  bottom: "conv5_3_1x1_increase"
  top: "conv5_3_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv5_3_1x1_down"
  type: "Convolution"
  bottom: "conv5_3_global_pool"
  top: "conv5_3_1x1_down"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_3_1x1_down/relu"
  type: "ReLU"
  bottom: "conv5_3_1x1_down"
  top: "conv5_3_1x1_down"
}
layer {
  name: "conv5_3_1x1_up"
  type: "Convolution"
  bottom: "conv5_3_1x1_down"
  top: "conv5_3_1x1_up"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_3_prob"
  type: "Sigmoid"
  bottom: "conv5_3_1x1_up"
  top: "conv5_3_1x1_up"
}
layer {
  name: "conv5_3"
  type: "Axpy"
  bottom: "conv5_3_1x1_up"
  bottom: "conv5_3_1x1_increase"
  bottom: "conv5_2"
  top: "conv5_3"
}
layer {
  name: "conv5_3/relu"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}

#----------------------------------------------------------------

layer {
  name: "global_info"
  type: "Convolution"
  bottom: "conv5_3_1x1_down"
  top: "global_info"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
  }
}

layer {
  name: "global_info_tile"
  type: "Tile"
  bottom: "global_info"
  top: "global_info_tile"
  tile_param {
    axis: 2
    tiles: 49
  }
}

layer {
	bottom: "global_info_tile"
	top: "global_info_reshape"
	name: "global_info_reshape"
	type: "Reshape"
	reshape_param {
		shape {
			dim: 0
			dim: 0
			dim: 7
      dim: 7
		}
	}
}

layer {
	bottom: "conv5_3"
	top: "local_info"
	name: "local_info"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
  name: "sum_info"
  type: "Eltwise"
  bottom: "global_info_reshape"
  bottom: "local_info"
  top: "sum_info"
  eltwise_param {
    operation: SUM
  }
}
 
layer {
	bottom: "sum_info"
	top: "sum_info"
	name: "sum_info_tanh"
	type: "TanH"
}

layer {
	bottom: "conv5_3"
	top: "pred_attribute_map"
	name: "pred_attribute_map"
	type: "Convolution"
	convolution_param {
		num_output: 26
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	bottom: "pred_attribute_map"
	top: "pred_attribute_map_reshape"
	name: "pred_attribute_map_reshape"
	type: "Reshape"
	reshape_param {
		shape {
			dim: 0
			dim: 0
			dim: -1
		}
	}
}

layer {
	bottom: "sum_info"
	top: "attention_map"
	name: "attention_map"
	type: "Convolution"
	convolution_param {
		num_output: 26
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	bottom: "attention_map"
	top: "attention_map_reshape"
	name: "attention_map_reshape"
	type: "Reshape"
	reshape_param {
		shape {
			dim: 0
			dim: 0
			dim: -1
		}
	}
}

layer {
	bottom: "attention_map_reshape"
	top: "attention_map_softmax"
	name: "attention_map_softmax"
	type: "Softmax"
	softmax_param {
		axis: 2
	}
}

layer {
	bottom: "pred_attribute_map_reshape"
	bottom: "attention_map_softmax"
	top: "attended_map"
	name: "attended_map"
	type: "Eltwise"
	eltwise_param {
		operation: PROD
	}
}

layer {
	bottom: "attended_map"
	top: "pred_attribute"
	name: "pred_attribute"
	type: "Reduction"
	reduction_param {
		operation: SUM
		axis: 2
	}
}

layer {
	type: 'Python'
	name: "weighted_loss"
	top: "weighted_loss"
	bottom: "pred_attribute"
	bottom: "gt_regression_attribute"
	propagate_down: 1
	propagate_down: 0
	python_param {
		module: "python_loss_layer"
		layer: "TrainValWeightedSigmoidCrossEntropyLossLayer"
	}
	loss_weight: 1
	loss_param {
		ignore_label: -1
	}
	include {
		phase: TRAIN
	}
}

layer {
	type: 'Python'
	name: "weighted_loss"
	top: "weighted_loss"
	bottom: "pred_attribute"
	bottom: "gt_regression_attribute"
	propagate_down: 1
	propagate_down: 0
	python_param {
		module: "python_loss_layer"
		layer: "SigmoidCrossEntropyLossLayer"
	}
	loss_weight: 1
	loss_param {
		ignore_label: -1
	}
	include {
		phase: TEST
	}
}
